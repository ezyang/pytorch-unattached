{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfering a model from PyTorch to Caffe2 and Mobile using ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we describe how to use ONNX to convert a model defined in PyTorch into the ONNX format and then load it into Caffe2. Once in Caffe2, we can run the model to double-check it was exported correctly, and we then show how to use Caffe2 features such as mobile exporter for executing the model on mobile devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some standard imports\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "\n",
    "import onnx\n",
    "import onnx.backend\n",
    "import onnx.backend.caffe2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we will transfer a super-resolution model as an example. First, let's create a SuperResolution model in PyTorch. [This model](https://github.com/pytorch/examples/blob/master/super_resolution/model.py) comes directly from PyTorch's examples without modification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Super Resolution model definition in PyTorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "class SuperResolutionNet(nn.Module):\n",
    "    def __init__(self, upscale_factor, inplace=False):\n",
    "        super(SuperResolutionNet, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal(self.conv4.weight)\n",
    "\n",
    "# Create the super-resolution model by using the above model definition.\n",
    "torch_model = SuperResolutionNet(upscale_factor=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinarily, you would now train this model; however, for this tutorial, we will instead download some pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperResolutionNet (\n",
       "  (relu): ReLU ()\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pixel_shuffle): PixelShuffle (upscale_factor=3)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model weights\n",
    "model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'\n",
    "batch_size = 1    # just a random number\n",
    "\n",
    "# Initialize model with the pretrained weights\n",
    "torch_model.load_state_dict(model_zoo.load_url(model_url))\n",
    "\n",
    "# set the train mode to false since we will only run the forward pass.\n",
    "torch_model.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Exporting a model in PyTorch works via tracing. To export a model, you call the `torch.onnx._export()` function. This will execute the model, recording a trace of what operators are used to compute the outputs. Because `export` runs the model, we need provide an input tensor `x`. The values in this tensor are not important; it can be an image or a random tensor as long as it is the right size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input to the model\n",
    "x = Variable(torch.randn(batch_size, 1, 224, 224), requires_grad=True)\n",
    "\n",
    "# Export the model\n",
    "torch_out = torch.onnx._export(torch_model,             # model being run \n",
    "                               x,                       # model input (or a tuple for multiple inputs) \n",
    "                               \"super_resolution.onnx\", # where to save the model (can be a file or file-like object)\n",
    "                               export_params=True)      # store the trained parameter weights inside the model file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch_out` is the output after executing the model. Normally you can ignore this output, but here we will use it to verify that the model we exported computes the same values when run in Caffe2.\n",
    "\n",
    "\n",
    "Now let's take the ONNX representation and use it in Caffe2. This part can normally be done in a separate process or on another machine, but we will continue in the same process so that we can verify that Caffe2 and PyTorch are computing the same value for the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the ONNX GraphProto object. Graph is a standard Python protobuf object\n",
    "graph = onnx.load(\"super_resolution.onnx\")\n",
    "\n",
    "# prepare the caffe2 backend for executing the model this converts the ONNX graph into a \n",
    "# Caffe2 NetDef that can execute it. Other ONNX backends, like one for CNTK will be \n",
    "# availiable soon.\n",
    "prepared_backend = onnx.backend.caffe2.prepare(graph)\n",
    "\n",
    "# run the model in Caffe2\n",
    "\n",
    "# Construct a map from input names to Tensor data.\n",
    "# The graph itself contains inputs for all weight parameters, followed by the input image.\n",
    "# Since the weights are already embedded, we just need to pass the input image.\n",
    "# last input the graph\n",
    "W = {graph.input[-1]: x.data.numpy()}\n",
    "\n",
    "# Run the Caffe2 net:\n",
    "c2_out = prepared_backend.run(W)[0]\n",
    "\n",
    "# Verify the numerical correctness upto 3 decimal places\n",
    "np.testing.assert_almost_equal(torch_out.data.cpu().numpy(), c2_out, decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfering SRResNet using ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super-resolution is a way of increasing the resolution of images, videos and is widely used in image processing or video editing. For the purpose of tutorial, we used a small super-resolution model with a dummy input above but using the steps above, we also transferred the SRResNet model for super-resolution presented in [this paper](https://arxiv.org/pdf/1609.04802.pdf). The model definition and a pre-trained model are available [here](https://gist.github.com/prigoyal/b245776903efbac00ee89699e001c9bd). Below is what super-resolution model input, output looks like. <img src=\"SRResNet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model on mobile devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have exported a model from PyTorch and shown how to load it and run it in Caffe2. Now that the model is loaded in Caffe2, we can convert it into a format suitable for [running on mobile devices](https://caffe2.ai/docs/mobile-integration.html).\n",
    "\n",
    "We will use Caffe2's [mobile_exporter](https://github.com/caffe2/caffe2/blob/master/caffe2/python/predictor/mobile_exporter.py) to generate the two model protobufs that can run on mobile. The first is used to initialize the network with the correct weights, and the second actual runs executes the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the workspace and the graph proto from the internal representation\n",
    "c2_workspace = prepared.workspace\n",
    "c2_graph = prepared.predict_net\n",
    "\n",
    "# Now import the caffe2 mobile exporter\n",
    "from caffe2.python.predictor import mobile_exporter\n",
    "\n",
    "# call the Export to get the predict_net, init_net\n",
    "# init_net, predict_net = mobile_exporter.Export(c2_workspace, c2_graph, c2_graph.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now, on your ios/Android device, you can use the above protobufs and use caffe2::Predictor (iOS) or Caffe2 instance (Android) for deploying them real-time. For more information, also checkout caffe2 https://caffe2.ai/docs/AI-Camera-demo-android.html</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
